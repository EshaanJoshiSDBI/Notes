{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb8b659b-977f-4784-a5ff-f4a5ddae7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import Word, TextBlob\n",
    "# from pattern.en import lemma, lexeme\n",
    "from nltk.stem import PorterStemmer\n",
    "cvectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "vectorizer = TfidfVectorizer(use_idf=True,ngram_range=(1,1))\n",
    "lem = WordNetLemmatizer()\n",
    "punct = list(punctuation)\n",
    "sw = stopwords.words('english')\n",
    "sp_char = [':','...',\"'\",\"''\",'``']\n",
    "# from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631a7268-8fb7-4c9b-a52a-8105a2a1a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac836c8c-3760-4062-8177-b3b48c44ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.DataFrame()\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3dbde3b-591c-45c8-abce-50513c66b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "690506b2-dfd3-42be-acc8-f8f9d70f7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(text,stem=False,lem_type='wordnet'):\n",
    "    txt = text.lower()\n",
    "    txt = re.sub(r'\\d+','',txt)\n",
    "    tkns = word_tokenize(txt)\n",
    "    tkns = [i for i in tkns if i not in sw and i not in sp_char and i not in punct]\n",
    "    tkns = [i for i in tkns if i.isalpha()]\n",
    "    def wordnet_lemmatize(tkns):\n",
    "        def pos_tag_simplified(tag):\n",
    "            if tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return None\n",
    "        tgs = nltk.pos_tag(tkns)\n",
    "        wtgs = list(map(lambda x: (x[0],pos_tag_simplified(x[1])),tgs))\n",
    "        lemmatized = []\n",
    "        for i in wtgs:\n",
    "            if i[1] != None:\n",
    "                lemmatized.append(lem.lemmatize(i[0],i[1]))\n",
    "            else:\n",
    "                lemmatized.append(lem.lemmatize(i[0]))\n",
    "        return lemmatized\n",
    "    def textblob_lemmatize(tkns):\n",
    "        sent = ' '.join(tkns)\n",
    "        sent = TextBlob(sent)\n",
    "        tag_dict = {'J':'a','N':'n','V':'v','R':'r'}\n",
    "        rds_tags = [(i,tag_dict.get(ii[0],'n')) for i,ii in sent.tags]\n",
    "        leml = [i.lemmatize(tag) for i,tag in rds_tags]\n",
    "        return leml\n",
    "    def pattern_lemmatize(tkns):\n",
    "        sent = ' '.join(tkns)\n",
    "        return \" \".join([lemma(wd) for wd in sent.split()])\n",
    "    def stemmer(tkns):\n",
    "        pr = PorterStemmer()\n",
    "        stemmed = [pr.stem(i) for i in tkns]\n",
    "        return ' '.join(stemmed)\n",
    "    if stem:\n",
    "        res = stemmer(tkns)\n",
    "    elif lem_type.lower() == 'wordnet':\n",
    "        res = wordnet_lemmatize(tkns)\n",
    "    elif lem_type.lower() == 'pattern':\n",
    "        res = pattern_lemmatize(tkns)\n",
    "    elif lem_type.lower() == 'textblob':\n",
    "        res = textblob_lemmatize(tkns)\n",
    "    # print(res)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77b6a99f-2ab8-4969-a2d0-99dca30780f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(data,stem=False,lem_type='wordnet',vectorizer='tfidf'):\n",
    "    # f = None\n",
    "    # global vec_df\n",
    "    # def check_idf():\n",
    "        # if f == None:\n",
    "        #     f = input('Want to use IDF ?(Y/N)')\n",
    "        #     return True\n",
    "        # else:\n",
    "        #     return False\n",
    "    # flst = list(processor(lst,stem,lem_type))\n",
    "    # # print(flst)\n",
    "    # return ' '.join(flst)\n",
    "    # return flst\n",
    "    data['clean_text'] = data['text'].apply(lambda x:processor(x,stem=stem,lem_type=lem_type))\n",
    "    print(data['clean_text'][:5])\n",
    "    def bow_vectorizer(data):\n",
    "        bow = cvectorizer.fit_transform(data['clean_text'])\n",
    "        df_bow = pd.DataFrame(bow.toarray(),columns=cvectorizer.get_feature_names_out())\n",
    "        return df_bow\n",
    "    def tfidf_vectorizer(data):\n",
    "        f = input('Want to use IDF ?(Y/N)')\n",
    "        if f.lower() == 'y':\n",
    "            vectorizer = TfidfVectorizer(use_idf=True,ngram_range=(1,1))\n",
    "            # print('here')\n",
    "        else:\n",
    "            vectorizer = TfidfVectorizer(use_idf=False,ngram_range=(1,1))\n",
    "        tfidf = vectorizer.fit_transform(data['clean_text'])\n",
    "        df_tfidf = pd.DataFrame(tfidf.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "        return df_tfidf\n",
    "    if vectorizer.lower() == 'tfidf':\n",
    "        res = tfidf_vectorizer(data)\n",
    "    else:\n",
    "        res = bow_vectorizer(data)\n",
    "    return data,res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4629b155-8264-4cb6-acf3-0b87d64a525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           virginamerica dhepburn say\n",
      "1    virginamerica plus added commercial experience...\n",
      "2    virginamerica today must mean need take anothe...\n",
      "3    virginamerica really aggressive blast obnoxiou...\n",
      "4                   virginamerica really big bad thing\n",
      "Name: clean_text, dtype: object\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Want to use IDF ?(Y/N) y\n"
     ]
    }
   ],
   "source": [
    "df,vec_df = vectorizer(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7c4eb-a4c7-4599-8f97-bff541abc36b",
   "metadata": {},
   "source": [
    "```pyth\n",
    "df['clean_text'] = df['text'].apply(lambda x:vectorizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcda1f0a-02c2-4e04-9f08-9159ab93739f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>virginamerica dhepburn say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>americanair thank get different flight chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>americanair leave minute late flight warning c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>americanair please bring american airline blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>americanair money change flight answer phone s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>americanair ppl need know many seat next fligh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                    @VirginAmerica What @dhepburn said.   \n",
       "1      @VirginAmerica plus you've added commercials t...   \n",
       "2      @VirginAmerica I didn't today... Must mean I n...   \n",
       "3      @VirginAmerica it's really aggressive to blast...   \n",
       "4      @VirginAmerica and it's a really big bad thing...   \n",
       "...                                                  ...   \n",
       "14635  @AmericanAir thank you we got on a different f...   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637  @AmericanAir Please bring American Airlines to...   \n",
       "14638  @AmericanAir you have my money, you change my ...   \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                                              clean_text  \n",
       "0                             virginamerica dhepburn say  \n",
       "1      virginamerica plus added commercial experience...  \n",
       "2      virginamerica today must mean need take anothe...  \n",
       "3      virginamerica really aggressive blast obnoxiou...  \n",
       "4                     virginamerica really big bad thing  \n",
       "...                                                  ...  \n",
       "14635     americanair thank get different flight chicago  \n",
       "14636  americanair leave minute late flight warning c...  \n",
       "14637  americanair please bring american airline blac...  \n",
       "14638  americanair money change flight answer phone s...  \n",
       "14639  americanair ppl need know many seat next fligh...  \n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text','clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7213383b-fef4-40f1-a307-536a252a99f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaadvantage</th>\n",
       "      <th>aaalwayslate</th>\n",
       "      <th>aacustomerservice</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadelay</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aafail</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zj</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zrh</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaand  aaadvantage  aaalwayslate  aacustomerservice  aadavantage  \\\n",
       "0  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "1  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "2  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "3  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "4  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "\n",
       "   aadelay  aadv  aadvantage  aafail  ...  zip  zipper   zj  zkatcher  zombie  \\\n",
       "0      0.0   0.0         0.0     0.0  ...  0.0     0.0  0.0       0.0     0.0   \n",
       "1      0.0   0.0         0.0     0.0  ...  0.0     0.0  0.0       0.0     0.0   \n",
       "2      0.0   0.0         0.0     0.0  ...  0.0     0.0  0.0       0.0     0.0   \n",
       "3      0.0   0.0         0.0     0.0  ...  0.0     0.0  0.0       0.0     0.0   \n",
       "4      0.0   0.0         0.0     0.0  ...  0.0     0.0  0.0       0.0     0.0   \n",
       "\n",
       "   zone  zoom  zrh  zukes  zurich  \n",
       "0   0.0   0.0  0.0    0.0     0.0  \n",
       "1   0.0   0.0  0.0    0.0     0.0  \n",
       "2   0.0   0.0  0.0    0.0     0.0  \n",
       "3   0.0   0.0  0.0    0.0     0.0  \n",
       "4   0.0   0.0  0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
